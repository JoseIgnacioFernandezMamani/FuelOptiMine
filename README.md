# AI data assistant

AquÃ­ tienes el README.md unificado para el monorepo, integrando todas las componentes tÃ©cnicas y documentaciÃ³n:

## Sistema Inteligente de OptimizaciÃ³n Minera - Minera San CristÃ³bal

[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/Python-3.10%2B-blue.svg)](https://www.python.org/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

## diagrama c4 de contexto

flowchart TD  
    A[Operarios] <--> B{{Dashboard Streamlit}}  
    B <--> C[API FastAPI]  
    C <--> D[Modelos XGBoost]  
    C <--> E[Optimizador MILP]  
    D <--> F[SQL Server]  
    E <--> G[Hexagon Mining]  

## ğŸŒŸ VisiÃ³n General

Sistema predictivo y de optimizaciÃ³n para la gestiÃ³n inteligente de recursos en minerÃ­a a cielo abierto, integrando:

- **Modelos Predictivos** (Series temporales, RegresiÃ³n avanzada)
- **IA Operativa** (AnÃ¡lisis contextual con Mistral-7B)
- **Dashboard Interactivo** (VisualizaciÃ³n en tiempo real)
- **Sistema de Reportes Automatizados** (PDF/Excel)
- **Arquitectura Offline-First** (Funcionalidad en redes restringidas)

**Objetivo Principal**: Reducir el consumo de diÃ©sel en operaciones mineras entre 5-15% mediante optimizaciÃ³n dinÃ¡mica.

## ğŸš€ CaracterÃ­sticas Clave

| MÃ³dulo                  | TecnologÃ­as Clave                              | DescripciÃ³n                                                       |
| ----------------------- | ---------------------------------------------- | ----------------------------------------------------------------- |
| **NÃºcleo AnalÃ­tico**    | `pandas`, `scipy`, `numpy`                     | Procesamiento de datos histÃ³ricos y en tiempo real                |
| **Modelado Predictivo** | `scikit-learn`, `XGBoost`, `mlflow`                      | Modelos de regresiÃ³n lineal y boosting para predicciÃ³n de consumo |
| **VisualizaciÃ³n**       | `plotly`, `streamlit`, `matplotlib`, `seaborn` | GrÃ¡ficos interactivos y anÃ¡lisis espacial                         |
| **OptimizaciÃ³n**        | `pulp`, `scipy.optimize`                       | Algoritmos MILP para rutas y asignaciÃ³n de recursos               |
| **IA Contextual**       | `transformers`, `Mistral-7B`                   | AnÃ¡lisis de eventos no estructurados y NLP                        |
| **Infraestructura**     | `uvicorn`, `fastAPI`              | Backend performante y frontend intuitivo                          |

## ğŸ—ï¸ Arquitectura del Sistema

```mermaid
flowchart TD
    %% Sensores y Flujo de Datos
    subgraph Sensores["ğŸ“Ÿ Sensores IoT en Equipos Mineros"]
        S1["ğŸšš CamiÃ³n - Sensor DiÃ©sel"]
        S2["â›ï¸ Excavadora - Sensor Carga"]
        S3["ğŸ› ï¸ Equipo Auxiliar - VibraciÃ³n"]
    end

    %% Bases de Datos
    subgraph BDs["ğŸ—„ï¸ Capa de Datos"]
        PostgREST["ğŸ”„ PostgREST (Tiempo Real)"]
        SQL["ğŸ“¦ SQL Server (Reportes)"]
    end

    %% Procesamiento
    subgraph Backend["ğŸ–¥ï¸ Backend de Procesamiento"]
        AnalÃ­tico["ğŸ§® NÃºcleo AnalÃ­tico\npandas/scipy/numpy"]
        Modelos["ğŸ¤– Modelado Predictivo\nscikit-learn/XGBoost"]
        OptimizaciÃ³n["âš™ï¸ OptimizaciÃ³n MILP\nPuLP/scipy.optimize"]
        IA["ğŸ§  IA Contextual\ntransformers/Mistral-7B"]
    end

    %% Frontend
    subgraph Frontend["ğŸ“Š Interfaz Operativa"]
        Streamlit["ğŸš€ Dashboard Streamlit\nplotly/matplotlib"]
        Reportes["ğŸ“„ Generador de Reportes\nPDF/Excel"]
    end

    %% Flujo Principal
    Sensores -->|Datos en Tiempo Real| PostgREST
    PostgREST -->|Copia Incremental| SQL
    SQL -->|ODBC| Backend
    Backend -->|FastAPI| Streamlit
    Backend -->|WebSocket| IA
    Streamlit -->|AutomatizaciÃ³n| Reportes

    %% Estilos
    classDef sensores fill:#E8F5E9,stroke:#4CAF50,stroke-width:2px
    classDef bd fill:#E3F2FD,stroke:#2196F3,stroke-width:2px
    classDef backend fill:#FBE9E7,stroke:#FF5722,stroke-width:2px
    classDef frontend fill:#FFF3E0,stroke:#FF9800,stroke-width:2px

    class Sensores sensores
    class BDs bd
    class Backend backend
    class Frontend frontend
```

## ğŸ“¦ Estructura del Monorepo

```bash
FuelOptiMine/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/                  # ğŸ” Flujos de CI/CD automatizados
â”‚       â”œâ”€â”€ tests.yml               # Ejecuta pytest + flake8 en cada PR
â”‚       â”œâ”€â”€ model-training.yml      # Entrena modelos nightly con datos actualizados
â”‚       â””â”€â”€ deploy-prod.yml         # Despliegue en AWS/GCP tras merge a main
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ models/                     # ğŸ“œ DocumentaciÃ³n tÃ©cnica detallada (ESPEJO del cÃ³digo)
â”‚       â”œâ”€â”€ predictive/
â”‚       â”‚   â”œâ”€â”€ lineal/
â”‚       â”‚   â””â”€â”€ xgboost/
â”‚       â””â”€â”€ optimize/
â”‚           â”œâ”€â”€ milp/
â”‚
â”œâ”€â”€ model/                          # ğŸ’ NÃºcleo del Sistema (MLOps)
â”‚   â”œâ”€â”€ predictive/
â”‚   â”‚   â”œâ”€â”€ xgboost/
â”‚   â”‚   â”‚   â”œâ”€â”€ train/              # ğŸš‚ Entrenamiento
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ pipeline.py     # Flujo completo (prepro â†’ entrenamiento â†’ serializaciÃ³n)
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ hyperparams/    # Configuraciones para Optuna (study.yml)
â”‚   â”‚   â”‚   â”œâ”€â”€ evaluate/           # ğŸ“ˆ EvaluaciÃ³n
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ metrics.py      # CÃ¡lculo de MAE, RMSE, RÂ²
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ explainability/ # SHAP/LIME (notebooks interactivos)
â”‚   â”‚   â”‚   â””â”€â”€ registry/           # ğŸ—ƒï¸ Model Registry (MLflow)
â”‚   â”‚   â”‚       â”œâ”€â”€ v1.2.3/         # VersiÃ³n semÃ¡ntica con metadatos
â”‚   â”‚   â”‚       â””â”€â”€ champion/       # Enlace al mejor modelo actual
â”‚   â”‚   â””â”€â”€ linear-regression/      # regresiones lineales
â”‚   â”‚       â””â”€â”€ diagnostic/         # âœ… ValidaciÃ³n de supuestos (Durbin-Watson, VIF)
â”‚   â”œâ”€â”€ optimize/
â”‚   â”‚   â”œâ”€â”€ milp/
â”‚   â”‚   â”‚   â”œâ”€â”€ formulation/        # ğŸ“ Modelos matemÃ¡ticos (archivos .lp/.mod)
â”‚   â”‚   â”‚   â”œâ”€â”€ solver/             # âš™ï¸ ConfiguraciÃ³n de solvers (Gurobi/CPLEX)
â”‚   â”‚   â”‚   â””â”€â”€ scenarios/          # ğŸ§ª Casos de prueba (precio diÃ©sel +10%, falla de camiÃ³n)
â”‚   â”‚   â””â”€â”€ validation/             # âœ… Pruebas contra soluciones conocidas
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ data_validation/        # ğŸ›¡ï¸ Pipeline de calidad (Great Expectations)
â”‚       â”œâ”€â”€ transformers/           # ğŸ”„ Custom transformers (sklearn API)
â”‚       â””â”€â”€ drift_detection/        # ğŸ“¡ Monitoreo de concepto (ADWIN/KL-divergence)
â”‚
â”‚
â”œâ”€â”€ backend/                        # âš™ï¸ Backend (Clean Architecture)
â”‚   â””â”€â”€ api/
â”‚       â”œâ”€â”€ routers/                # ğŸ•¸ï¸ Endpoints modulares
â”‚       â”‚   â”œâ”€â”€ predict.py          # âœ… ValidaciÃ³n con Pydantic v2
â”‚       â”‚   â”œâ”€â”€ optimize.py         # ğŸ”„ Async support para operaciones largas
â”‚       â”‚   â””â”€â”€ diagnostics/        # ğŸ©º Health checks, mÃ©tricas Prometheus
â”‚       â”œâ”€â”€ middleware/             # ğŸ”’ Seguridad y auditorÃ­a
â”‚       â”‚   â”œâ”€â”€ auth.py             # JWT/OAuth2
â”‚       â”‚   â””â”€â”€ rate_limiter.py     # Bucket token algorithm
â”‚       â””â”€â”€ schemas/                # ğŸ“¦ Tipos de datos (TypeScript-like)
â”œâ”€â”€ analytics/
â”‚   â”œâ”€â”€ eda/     # EDA en tiempo real (servicios)
â”‚   â”‚   â”œâ”€â”€ distribucion_temporal.py  # Ej: consumo por hora
â”‚   â”‚   â””â”€â”€ densidad_consumo.py       # KDE por tipo de camiÃ³n
â”‚   â”‚
â”‚   â”œâ”€â”€ feature_engineer/          # Features en producciÃ³n
â”‚   â”‚   â””â”€â”€ calcular_metricas.py      # Ej: eficiencia = toneladas/litro
â”‚   â”‚
â”‚   â””â”€â”€ reports/                     # GeneraciÃ³n automÃ¡tica
â”‚       â”œâ”€â”€ pdf_builder.py            # Reportes PDF
â”‚       â””â”€â”€ excel_generator.py        # Exportar a Excel
â”œâ”€â”€ ia/
â”‚   â”œâ”€â”€ nlp/                    # ğŸ—£ï¸ Procesamiento de lenguaje
â”‚   â”‚   â”œâ”€â”€ embeddings/         # Custom embeddings (sentence-transformers)
â”‚   â”‚   â””â”€â”€ postprocessing      # ğŸ§© Rule-based correction
â”‚   â”œâ”€â”€ finetuning/             # âš™ï¸ Ajuste Mistral-7B (LoRA/QLoRA)
â”‚   â””â”€â”€ evaluation/             # ğŸ“Š MÃ©tricas LLM (BLEU, ROUGE, BERTScore)
â”‚
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ extractors/
â”‚   â”‚   â”œâ”€â”€ base_extractor.py    # Clase padre con logging/errores
â”‚   â”‚   â”œâ”€â”€ fuel_extractor.py    # EspecÃ­fico para CSV de combustible
â”‚   â”‚   â”œâ”€â”€ sensor_extractor.py  # Lee JSON de sensores IoT
â”‚   â”‚   â””â”€â”€ validation_data_extractor.py  # Lee JSON de sensores IoT
â”‚   â”‚
â”‚   â”œâ”€â”€ transformers/
â”‚   â”‚   â”œâ”€â”€ base_transformer.py  # MÃ©todos para columnas comunes
â”‚   â”‚   â”œâ”€â”€ fuel_transformer.py  # Calcula litros desde galones
â”‚   â”‚   â”œâ”€â”€ sensor_transformer.py # Convierte unidades de vibraciÃ³n
â”‚   â”‚   â””â”€â”€ validation_data_transformer.py # Convierte unidades de vibraciÃ³n
â”‚   â”‚
â”‚   â”œâ”€â”€ loaders/
â”‚   â”‚   â”œâ”€â”€ base_loader.py       # ConexiÃ³n genÃ©rica a DB
â”‚   â”‚   â”œâ”€â”€ fuel_loader.py       # Inserta en tabla fuel_metrics
â”‚   â”‚   â”œâ”€â”€ sensor_loader.py     # Carga en time_series_db
â”‚   â”‚   â””â”€â”€ validation_data_loader.py     # Carga en time_series_db
â”‚   â”‚
â”‚   â”œâ”€â”€ pipelines/               # ğŸ›ï¸ Combinaciones especÃ­ficas
â”‚   â”‚   â”œâ”€â”€ fuel_pipeline.py     # FuelExtractor â†’ FuelTransformer â†’ FuelLoader
â”‚   â”‚   â””â”€â”€ sensor_pipeline.py   # SensorExtractor â†’ SensorTransformer â†’ SensorLoader
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ validators.py        # Verifica columnas comunes
â”‚       â””â”€â”€ schema_tools.py      # Mapeo de nombres de columnas
â”‚
â”œâ”€â”€ interfaces/
â”‚    â””â”€â”€ web/                        # ğŸŒ Interfaz Web Principal (Streamlit)
â”‚       â”œâ”€â”€ app/                    
â”‚       â”‚   â”œâ”€â”€ pages/              # Vistas independientes
â”‚       â”‚   â”‚   â”œâ”€â”€ 01_ğŸ _Dashboard.py     # Vista principal con mÃ©tricas
â”‚       â”‚   â”‚   â”œâ”€â”€ 02_ğŸ“ˆ_Predicciones.py  # ConfiguraciÃ³n y resultados
â”‚       â”‚   â”‚   â”œâ”€â”€ 03_âš™ï¸_Simulaciones.py  # Escenarios what-if
â”‚       â”‚   â”‚   â””â”€â”€ 04_ğŸ“‘_Reportes.py      # GeneraciÃ³n de documentos
â”‚       â”‚   â”œâ”€â”€ app.py         
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ components/         # Componentes personalizados
â”‚       â”‚   â”‚   â”œâ”€â”€ charts/         # GrÃ¡ficos reutilizables
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ fuel_flow.py       # Diagrama Sankey personalizado
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ time_series.py     # Serie temporal interactiva
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ model_selector.py  # Selector de versiÃ³n de modelos
â”‚       â”‚   â”‚   â”‚   â””â”€â”€ data_uploader.py   # Uploader con preprocesamiento
â”‚       â”‚   â”‚   â”‚
â”‚       â”‚   â”‚   â””â”€â”€ templates/      # Plantillas HTML/Jinja2
â”‚       â”‚   â”‚       â””â”€â”€ report_base.html   # Base para PDF/HTML
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ assets/             # Recursos estÃ¡ticos
â”‚       â”‚   â”‚   â”œâ”€â”€ themes/         # Temas personalizados
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ dark.py     # ConfiguraciÃ³n tema oscuro
â”‚       â”‚   â”‚   â”‚   â””â”€â”€ mining.py   # Tema corporativo (colores marca)
â”‚       â”‚   â”‚   â”‚
â”‚       â”‚   â”‚   â”œâ”€â”€ icons/          # SVG optimizados
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ excavator.svg
â”‚       â”‚   â”‚   â”‚   â””â”€â”€ fuel-tank.svg
â”‚       â”‚   â”‚   â”‚
â”‚       â”‚   â”‚   â””â”€â”€ locales/        # InternacionalizaciÃ³n
â”‚       â”‚   â”‚       â”œâ”€â”€ es.json     # EspaÃ±ol
â”‚       â”‚   â”‚       â””â”€â”€ en.json     # InglÃ©s
â”‚       â”‚   â”‚
â”‚       â”‚   â””â”€â”€ utils/              # Utilidades especÃ­ficas
â”‚       â”‚       â”œâ”€â”€ api_client.py   # Cliente para backend
â”‚       â”‚       â””â”€â”€ formatters.py   # Formateo de datos
â”‚       â”‚
â”‚       â”œâ”€â”€ tests/                  # Pruebas especÃ­ficas de UI
â”‚       â”‚   â”œâ”€â”€ e2e/                # Pruebas completas
â”‚       â”‚   â”‚   â””â”€â”€ test_dashboard.py
â”‚       â”‚   â””â”€â”€ visual/             # Regression testing visual
â”‚       â”‚       â””â”€â”€ baseline_images # Capturas de referencia
â”‚       â”‚
â”‚       â””â”€â”€ config/                 # ConfiguraciÃ³n especÃ­fica
â”‚           â”œâ”€â”€ secrets.toml        # Credenciales (ignorado por git)
â”‚           â””â”€â”€ settings.py         # ParÃ¡metros de la app
â”‚
â”œâ”€â”€ data-set/                           # ğŸ“¦ GestiÃ³n de datos
â”‚   â”œâ”€â”€ connectors/                 # Adaptadores BD (PostgREST/SQL)
â”‚   â”œâ”€â”€ raw/                        # Datos crudos
â”‚   â””â”€â”€ processed/                  # Datos model-ready
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE                         # lICENCIA MIT
â”œâ”€â”€ README.md                       # â–¶ï¸ Punto de entrada principal
â”œâ”€â”€ requirements.txt                # â–¶ï¸ Dependencias del proyecto
â”œâ”€â”€ Makefile                        # ğŸ› ï¸ Comandos esenciales (train, test, deploy)
â”œâ”€â”€ pyproject.toml                  # ğŸ“¦ ConfiguraciÃ³n moderna de paquetes (PEP 621)
â”œâ”€â”€ CHANGELOG.md                    # ğŸ“† Historial de versiones (Keep a Changelog)
â””â”€â”€ SECURITY.md                     # ğŸ”’ PolÃ­tica de reporte de vulnerabilidades
```

## ğŸ’» Requisitos TÃ©cnicos

Entorno de Desarrollo

- Python 3.10.x
- RAM: 16GB mÃ­nimo (32GB recomendado para IA)
- 50GB de espacio libre
- ConexiÃ³n a instancia SQL Server

ProducciÃ³n (VMware)

- Ubuntu 22.04 LTS
- 8 nÃºcleos CPU
- 32GB RAM
- Python 3.10 con virtualenv

## ğŸ› ï¸ InstalaciÃ³n

```bash
# Clonar repositorio
git clone https://github.com/minera-sc/optimizacion-diesel.git
cd optimizacion-diesel

# Configurar entorno virtual
python -m venv .venv
source .venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt

# Descargar modelos IA (requiere Hugging Face Hub)
python scripts/download_models.py
```

## âš™ï¸ ConfiguraciÃ³n

1. Crear archivo `.env` en raÃ­z del proyecto:

```ini
SQL_SERVER=192.168.1.100
SQL_DATABASE=mineria_operaciones
SQL_USER=usuario_seguro
SQL_PASSWORD=clave_compleja
MISTRAL_MODEL_PATH=./models/mistral-7b-Q4_K_M.gguf
```

Ejecutar inicializaciÃ³n:

```bash
python backend/core/initialize_system.py
```

## ğŸ–¥ï¸ Uso

**Iniciar Servicios:**

```bash
# Backend (FastAPI)
uvicorn backend.api.main:app --host 0.0.0.0 --port 8000

# Frontend (Streamlit)
streamlit run frontend/dashboard.py --server.port 8501
```

**Acceso al Dashboard:**

- URL: `http://<vm-ip>:8501`
- Credenciales: `operaciones / MineraSC2024`

**Flujo de Trabajo:**

1. Cargar datos operativos diarios
2. Ejecutar predicciÃ³n de consumo
3. Optimizar rutas y asignaciones
4. Generar reporte automatizado
5. Ajustar parÃ¡metros vÃ­a asistente IA

## ğŸ§ª Testing

```bash
# Ejecutar pruebas unitarias
pytest tests/ --cov=backend --cov=frontend

# Pruebas de carga API
locust -f tests/load_test.py

# Validar modelos IA
python tests/validate_models.py
```

## ğŸš¢ Despliegue en ProducciÃ³n

1. Transferir proyecto a VM:

```bash
rsync -avz --progress ./ usuario@vm-mineria:/opt/optimizacion-diesel
```

Configurar servicio systemd:

```ini
# /etc/systemd/system/mineria-sc.service
[Unit]
Description=Sistema de OptimizaciÃ³n Minera SC
After=network.target

[Service]
User=mineria
WorkingDirectory=/opt/optimizacion-diesel
ExecStart=/usr/bin/bash infrastructure/vm_scripts/start_production.sh
Restart=always

[Install]
WantedBy=multi-user.target
```

Monitoreo:

```bash
journalctl -u mineria-sc.service -f
```

## ğŸ¤ ContribuciÃ³n

1. Hacer fork del repositorio
2. Crear rama feature:

```bash
git checkout -b feature/nueva-funcionalidad
```

3. Realizar commits descriptivos
4. Abrir Pull Request con documentaciÃ³n actualizada

## ğŸ“„ Licencia

MIT License - Ver [LICENSE](LICENSE) para detalles.

## ğŸ“§ Contacto

**Equipo de TecnologÃ­a Minera SC**  
âœ‰ï¸ soporte-tecnico@minera-sc.bo
ğŸ“ +591 2 123 4567  
ğŸŒ [www.minera-sc.bo](https://www.minera-sc.bo)

Este README unificado integra todos los componentes tÃ©cnicos del proyecto manteniendo coherencia con el `requirements.txt` proporcionado. Incluye:

- Arquitectura moderna con separaciÃ³n clara de componentes
- Flujos de trabajo para desarrollo y producciÃ³n
- IntegraciÃ³n con sistemas existentes de MSC
- Mecanismos de seguridad y monitoreo
- DocumentaciÃ³n completa para operaciÃ³n y mantenimiento

Para mantener la consistencia, ejecutar:

```bash

black . # Formateo de cÃ³digo
pylint backend/ frontend/ # VerificaciÃ³n de calidad

```


```mermaid
sequenceDiagram
    participant Sensores
    participant Validacion
    participant ETL_Core
    participant ModelRegistry
    participant Orchestrator
    participant Backend
    participant Interfaces
    participant Analytics
    participant Almacenamiento

    rect rgb(25, 55, 100)
    Note over Sensores,ETL_Core: Fase 1: Ingesta y Procesamiento
    Sensores->>ETL_Core: Stream datos IoT (MQTT/HTTP)
    Validacion->>ETL_Core: Datos histÃ³ricos (Batch)
    ETL_Core->>ETL_Core: ValidaciÃ³n Great Expectations
    alt Datos vÃ¡lidos
        ETL_Core->>Almacenamiento: Guardar en Data Lake (Parquet)
    else Datos invÃ¡lidos
        ETL_Core->>Orchestrator: Alerta de calidad
        Orchestrator->>Backend: Notificar error (WebSocket)
    end
    end

    rect rgb(40, 100, 60)
    Note over Orchestrator,ModelRegistry: Fase 2: Entrenamiento Modelos
    Orchestrator->>Orchestrator: Programar tarea (Cron/Noche)
    Orchestrator->>ETL_Core: Solicitar datos entrenamiento
    ETL_Core->>Orchestrator: Dataset procesado
    Orchestrator->>ModelRegistry: Ejecutar pipeline ML (Kedro)
    ModelRegistry->>ModelRegistry: Entrenar modelo (XGBoost)
    ModelRegistry->>ModelRegistry: Evaluar mÃ©tricas (RMSE, MAE)
    ModelRegistry->>Almacenamiento: Versionar modelo (MLflow)
    ModelRegistry->>Analytics: Generar reporte explicativo (SHAP)
    end

    rect rgb(100, 40, 80)
    Note over Backend,Interfaces: Fase 3: InteracciÃ³n Usuario
    Interfaces->>Backend: POST /analyze (JWT)
    Backend->>Orchestrator: Disparar pipeline (Celery)
    Orchestrator->>ETL_Core: Obtener datos en tiempo real
    ETL_Core->>Orchestrator: Datos para predicciÃ³n
    Orchestrator->>ModelRegistry: Cargar modelo (v1.2.3)
    ModelRegistry->>Orchestrator: Resultado predicciÃ³n
    Orchestrator->>Analytics: Generar visualizaciones
    Analytics->>Almacenamiento: Guardar reporte PDF
    Orchestrator->>Backend: Respuesta estructurada
    Backend->>Interfaces: Dashboard (Streamlit/WebSocket)
    end

    rect rgb(80, 80, 80)
    Note over Analytics,Almacenamiento: Fase 4: Monitoreo Continuo
    loop Cada 6h
        Analytics->>ETL_Core: Obtener Ãºltimos datos
        Analytics->>ModelRegistry: Chequear drift (ADWIN)
        alt Drift detectado
            ModelRegistry->>Orchestrator: Solicitar reentrenamiento
            Orchestrator->>Backend: Notificar alerta
        end
    end
    end
```



## Buenas practicas

Entendido, me enfoquÃ© demasiado en ejemplos de cÃ³digo. Vamos a explicar los conceptos de forma clara:

# OrganizaciÃ³n de ETL y Buenas PrÃ¡cticas

## Sobre la estructura de directorios para ETL

El tÃ©rmino "Extract" en ETL no se limita solo a los datasets propios, sino que abarca cualquier fuente de datos:

- **Datasets propios/locales**: Archivos CSV, JSON, Excel, etc. que estÃ¡n almacenados localmente
- **Fuentes externas**: Bases de datos, APIs, servicios web, etc.

### DiferenciaciÃ³n entre fuentes

Para diferenciar claramente entre tipos de fuentes, es recomendable:

1. **Separar por subdirectorios**:
   - `extract/local/` - Para datasets propios
   - `extract/external/` - Para fuentes externas como bases de datos

2. **Usar nomenclatura clara**:
   - Los extractores de datasets propios pueden llamarse `FileExtractor`, `CSVExtractor`, etc.
   - Los extractores externos pueden llamarse `DatabaseExtractor`, `APIExtractor`, etc.

## Buenas prÃ¡cticas para un proyecto de anÃ¡lisis de datos

### 1. ProgramaciÃ³n Orientada a Objetos (POO)

- **Herencia**: Crea clases base abstractas para cada etapa (Extract, Transform, Load) y deriva implementaciones especÃ­ficas. Esto evita duplicaciÃ³n de cÃ³digo y establece un comportamiento comÃºn.

- **Encapsulamiento**: Oculta detalles de implementaciÃ³n mediante mÃ©todos privados, exponiendo solo interfaces limpias. Especialmente Ãºtil para algoritmos complejos de limpieza o transformaciÃ³n.

- **Polimorfismo**: Usa interfaces comunes para diferentes implementaciones. Por ejemplo, todos los extractores pueden tener un mÃ©todo `extract()` independientemente de la fuente.

- **ComposiciÃ³n sobre herencia**: Para funcionalidades complejas, considera componer objetos en lugar de crear jerarquÃ­as profundas de herencia.

### 2. Patrones de diseÃ±o Ãºtiles

- **Factory**: Crea objetos sin exponer la lÃ³gica de creaciÃ³n. Ãštil para instanciar diferentes tipos de extractores segÃºn la fuente.

- **Strategy**: Encapsula algoritmos intercambiables. Ideal para diferentes estrategias de transformaciÃ³n.

- **Singleton**: Para componentes que deben tener una Ãºnica instancia, como configuraciones o conexiones a bases de datos.

- **Observer**: Para notificar a mÃºltiples componentes sobre cambios en los datos o el estado del proceso ETL.

- **Decorator**: Para aÃ±adir funcionalidades como logging, validaciÃ³n o mediciÃ³n de rendimiento a cualquier componente ETL.

### 3. Buenas prÃ¡cticas adicionales

- **Manejo de excepciones personalizado**: Define jerarquÃ­as de excepciones especÃ­ficas para ETL para facilitar la identificaciÃ³n y manejo de problemas.

- **Logging comprehensivo**: Implementa logging detallado en cada etapa del proceso ETL para facilitar la depuraciÃ³n y monitoreo.

- **ValidaciÃ³n de datos**: Valida la estructura y contenido de los datos en cada etapa para detectar problemas temprano.

- **ConfiguraciÃ³n externalizada**: MantÃ©n parÃ¡metros en archivos de configuraciÃ³n en lugar de hardcodearlos en el cÃ³digo.

- **Testing automatizado**: Implementa pruebas unitarias y de integraciÃ³n para cada componente del sistema ETL.

- **DocumentaciÃ³n**: Documenta claramente cada clase y mÃ©todo con su propÃ³sito, parÃ¡metros, valores de retorno y ejemplos.

- **Versionado de datos**: MantÃ©n registro de las versiones de los datos procesados para facilitar la reproducibilidad.

- **Principio de responsabilidad Ãºnica**: Cada clase debe tener una Ãºnica responsabilidad, facilitando el mantenimiento.

- **Idempotencia**: Los procesos ETL deben poder ejecutarse mÃºltiples veces sin efectos secundarios no deseados.

- **Monitoreo de rendimiento**: Incluye mÃ©tricas para medir el rendimiento de cada etapa del ETL.

- **Control de transacciones**: Asegura que las operaciones sean atÃ³micas cuando sea necesario, especialmente en la fase de Load.

Siguiendo estas prÃ¡cticas, podrÃ¡s construir un sistema ETL robusto, mantenible y escalable que se adapte bien a las necesidades de un proyecto de anÃ¡lisis de datos y modelos matemÃ¡ticos de alto nivel.



estrcutura de cualquiern modulo:


modulo-nombre/  # Por ejemplo: extract/, transform/, o load/
â”‚
â”œâ”€â”€â”€core/  # Funcionalidad central y componentes bÃ¡sicos
â”‚   â”œâ”€â”€â”€__init__.py
â”‚   â”œâ”€â”€â”€base.py  # Clases e interfaces base
â”‚   â””â”€â”€â”€exceptions.py  # Excepciones especÃ­ficas del mÃ³dulo
â”‚
â”œâ”€â”€â”€interfaces/  # Contratos e interfaces del mÃ³dulo
â”‚   â”œâ”€â”€â”€__init__.py
â”‚   â””â”€â”€â”€[nombre_interfaz].py  # Interfaces especÃ­ficas
â”‚
â”œâ”€â”€â”€models/  # Modelos de datos y estructuras
â”‚   â”œâ”€â”€â”€__init__.py
â”‚   â””â”€â”€â”€[nombre_modelo].py  # Definiciones de modelos
â”‚
â”œâ”€â”€â”€implementations/  # Implementaciones concretas
â”‚   â”œâ”€â”€â”€__init__.py
â”‚   â”œâ”€â”€â”€[tipo_implementacion1]/
â”‚   â”‚   â”œâ”€â”€â”€__init__.py
â”‚   â”‚   â””â”€â”€â”€[implementacion_especifica].py
â”‚   â””â”€â”€â”€[tipo_implementacion2]/
â”‚       â”œâ”€â”€â”€__init__.py
â”‚       â””â”€â”€â”€[implementacion_especifica].py
â”‚
â”œâ”€â”€â”€utils/  # Utilidades especÃ­ficas del mÃ³dulo
â”‚   â”œâ”€â”€â”€__init__.py
â”‚   â””â”€â”€â”€[utilidad].py
â”‚
â”œâ”€â”€â”€config/  # Configuraciones
â”‚   â”œâ”€â”€â”€__init__.py
â”‚   â”œâ”€â”€â”€default.py  # Configuraciones por defecto
â”‚   â””â”€â”€â”€schemas.py  # Esquemas de validaciÃ³n para configuraciones
â”‚
â”œâ”€â”€â”€factories/  # Factories para crear instancias
â”‚   â”œâ”€â”€â”€__init__.py
â”‚   â””â”€â”€â”€[factory].py
â”‚
â”œâ”€â”€â”€tests/  # Pruebas unitarias y de integraciÃ³n
â”‚   â”œâ”€â”€â”€__init__.py
â”‚   â”œâ”€â”€â”€unit/
â”‚   â”‚   â””â”€â”€â”€test_[componente].py
â”‚   â””â”€â”€â”€integration/
â”‚       â””â”€â”€â”€test_[escenario].py
â”‚
â””â”€â”€â”€__init__.py  # Hace importable el mÃ³dulo y define interfaces pÃºblicas
